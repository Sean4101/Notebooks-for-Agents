{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from PO_grid_world import PO_GridWorld\n",
    "from notebook_env_wrapper import NotebookEnvWrapper\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_po = PO_GridWorld(partially_observable=True)\n",
    "env_notebook = NotebookEnvWrapper(PO_GridWorld(partially_observable=True), notebook_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrows = [\"↑\", \"↓\", \"←\", \"→\"]\n",
    "\n",
    "def print_policy(model):\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            obs = i*6 + j\n",
    "            pred = model.predict(obs, deterministic=True)[0]\n",
    "            print(arrows[pred], end=\" \")\n",
    "        print()\n",
    "\n",
    "def print_policy_po(po_model):\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            obs = (i//3)*2 + (j//3)\n",
    "            pred = po_model.predict(obs, deterministic=True)[0]\n",
    "            print(arrows[pred], end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↓ ↓ ↓ ↑ ↑ ↑ \n",
      "↓ ↓ ↓ ↑ ↑ ↑ \n",
      "↓ ↓ ↓ ↑ ↑ ↑ \n",
      "→ → → ↑ ↑ ↑ \n",
      "→ → → ↑ ↑ ↑ \n",
      "→ → → ↑ ↑ ↑ \n"
     ]
    }
   ],
   "source": [
    "model_po = PPO.load(\"models_cmp/ppo_gridworld_po_2\")\n",
    "print_policy_po(model_po)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO Model 0: 0.74 +/- 0.67\n",
      "PO Model 1: 0.73 +/- 0.69\n",
      "PO Model 2: 0.77 +/- 0.63\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "\n",
    "mean_rewards_po = []\n",
    "std_rewards_po = []\n",
    "\n",
    "for i in range(n):\n",
    "    model = PPO.load(f\"models_cmp/ppo_gridworld_po_{i}\")\n",
    "    mean_reward, std_reward = evaluate_policy(model, env_po, n_eval_episodes=1000)\n",
    "    mean_rewards_po.append(mean_reward)\n",
    "    std_rewards_po.append(std_reward)\n",
    "    print(f\"PO Model {i}: {mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Notebook\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Model 0: 0.88 +/- 0.48\n",
      "Notebook Model 1: 0.81 +/- 0.58\n",
      "Notebook Model 2: 0.81 +/- 0.50\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "\n",
    "mean_rewards_notebook = []\n",
    "std_rewards_notebook = []\n",
    "\n",
    "for i in range(n):\n",
    "    model = PPO.load(f\"models_cmp/ppo_gridworld_notebook_{i}\")\n",
    "    mean_reward, std_reward = evaluate_policy(model, env_notebook, n_eval_episodes=1000)\n",
    "    mean_rewards_notebook.append(mean_reward)\n",
    "    std_rewards_notebook.append(std_reward)\n",
    "    print(f\"Notebook Model {i}: {mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO models\n",
      "Mean reward: 0.75 +/- 0.66\n",
      "Notebook models\n",
      "Mean reward: 0.83 +/- 0.52\n"
     ]
    }
   ],
   "source": [
    "print(\"PO models\")\n",
    "print(f\"Mean reward: {np.mean(mean_rewards_po):.2f} +/- {np.mean(std_rewards_po):.2f}\")\n",
    "print(\"Notebook models\")\n",
    "print(f\"Mean reward: {np.mean(mean_rewards_notebook):.2f} +/- {np.mean(std_rewards_notebook):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
