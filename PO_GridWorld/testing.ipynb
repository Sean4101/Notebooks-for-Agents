{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from PO_grid_world import PO_GridWorld\n",
    "from notebook_env_wrapper import NotebookEnvWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Notebook\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward normal: 0.99 +/- 0.13\n",
      "Mean reward PO: 0.74 +/- 0.67\n",
      "Mean reward notebook: 0.89 +/- 0.45\n"
     ]
    }
   ],
   "source": [
    "# This code block is run when truncation hasn't been introduced\n",
    "# No longer relevant\n",
    "\n",
    "'''\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "mean_reward_norm, std_reward_norm = evaluate_policy(model_norm, env, n_eval_episodes=1000)\n",
    "mean_reward_po, std_reward_po = evaluate_policy(model_po, env_po, n_eval_episodes=1000)\n",
    "mean_reward_notebook, std_reward_notebook = evaluate_policy(model_notenook, env_notebook, n_eval_episodes=1000)\n",
    "\n",
    "print(f\"Mean reward normal: {mean_reward_norm:.2f} +/- {std_reward_norm:.2f}\")\n",
    "print(f\"Mean reward PO: {mean_reward_po:.2f} +/- {std_reward_po:.2f}\")\n",
    "print(f\"Mean reward notebook: {mean_reward_notebook:.2f} +/- {std_reward_notebook:.2f}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PO_GridWorld()\n",
    "env_po = PO_GridWorld(partially_observable=True)\n",
    "env_notebook = NotebookEnvWrapper(PO_GridWorld(partially_observable=True), notebook_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO Model 0 trained\n",
      "PO Model 1 trained\n",
      "PO Model 2 trained\n",
      "Notebook Model 0 trained\n",
      "Notebook Model 1 trained\n",
      "Notebook Model 2 trained\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "\n",
    "# Train n PO models\n",
    "for i in range(n):\n",
    "    model = PPO(\"MlpPolicy\", \n",
    "                env_po, \n",
    "                verbose=0,\n",
    "                learning_rate=0.0001,\n",
    "                gamma=0.9)\n",
    "    model.learn(total_timesteps=500000)\n",
    "    model.save(f\"models_cmp/ppo_gridworld_po_{i}\")\n",
    "    print(f\"PO Model {i} trained\")\n",
    "\n",
    "# Train n notebook models\n",
    "for i in range(n):\n",
    "    model = PPO(\"MlpPolicy\", \n",
    "                env_notebook, \n",
    "                verbose=0,\n",
    "                learning_rate=0.0001,\n",
    "                gamma=0.9)\n",
    "    model.learn(total_timesteps=500000)\n",
    "    model.save(f\"models_cmp/ppo_gridworld_notebook_{i}\")\n",
    "    print(f\"Notebook Model {i} trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_norm, model_po, model_notenook, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO Model 1: 0.80 +/- 0.60\n",
      "PO Model 3: 0.82 +/- 0.57\n",
      "PO Model 4: 0.90 +/- 0.44\n",
      "PO Model 5: 0.92 +/- 0.39\n",
      "PO Model 6: 0.90 +/- 0.44\n",
      "PO Model 7: 0.76 +/- 0.65\n",
      "PO Model 8: 0.88 +/- 0.47\n",
      "PO Model 9: 0.80 +/- 0.60\n",
      "Notebook Model 0: 0.78 +/- 0.63\n",
      "Notebook Model 1: 0.72 +/- 0.69\n",
      "Notebook Model 2: 0.80 +/- 0.60\n",
      "Notebook Model 3: 0.94 +/- 0.34\n",
      "Notebook Model 4: 0.92 +/- 0.39\n",
      "Notebook Model 5: 0.78 +/- 0.63\n",
      "Notebook Model 6: 0.72 +/- 0.69\n",
      "Notebook Model 7: 0.82 +/- 0.57\n",
      "Notebook Model 8: 0.52 +/- 0.85\n",
      "Notebook Model 9: 0.76 +/- 0.65\n",
      "PO models\n",
      "Mean reward: 0.85 +/- 0.52\n",
      "Notebook models\n",
      "Mean reward: 0.78 +/- 0.60\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models\n",
    "mean_rewards_po = []\n",
    "std_rewards_po = []\n",
    "mean_rewards_notebook = []\n",
    "std_rewards_notebook = []\n",
    "\n",
    "for i in range(n):\n",
    "    model = PPO.load(f\"models_cmp/ppo_gridworld_po_{i}\")\n",
    "    mean_reward, std_reward = evaluate_policy(model, env_po, n_eval_episodes=100)\n",
    "    mean_rewards_po.append(mean_reward)\n",
    "    std_rewards_po.append(std_reward)\n",
    "    print(f\"PO Model {i}: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "for i in range(n):\n",
    "    model = PPO.load(f\"models_cmp/ppo_gridworld_notebook_{i}\")\n",
    "    mean_reward, std_reward = evaluate_policy(model, env_notebook, n_eval_episodes=100)\n",
    "    mean_rewards_notebook.append(mean_reward)\n",
    "    std_rewards_notebook.append(std_reward)\n",
    "    print(f\"Notebook Model {i}: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "print(\"PO models\")\n",
    "print(f\"Mean reward: {np.mean(mean_rewards_po):.2f} +/- {np.mean(std_rewards_po):.2f}\")\n",
    "print(\"Notebook models\")\n",
    "print(f\"Mean reward: {np.mean(mean_rewards_notebook):.2f} +/- {np.mean(std_rewards_notebook):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
