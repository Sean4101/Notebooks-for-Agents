{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP0Ozf8/PbzAKftbKh8PiEx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%%bash\n","\n","pip install gymnasium==0.29.1\n","pip install gymnasium[atari]\n","pip install gymnasium[accept-rom-license]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"gyOZVLTWXb_J","executionInfo":{"status":"ok","timestamp":1732916828858,"user_tz":300,"elapsed":12760,"user":{"displayName":"Josh Mansky","userId":"05812403237052959145"}},"outputId":"1de669d5-c64c-481e-b9e9-d0915cbc2d4f"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gymnasium==0.29.1 in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.29.1) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.29.1) (3.1.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.29.1) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.29.1) (0.0.4)\n","Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (3.1.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (0.0.4)\n","Requirement already satisfied: shimmy<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]) (0.2.1)\n","Collecting ale-py~=0.8.1 (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari])\n","  Using cached ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]) (6.4.5)\n","Using cached ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","Installing collected packages: ale-py\n","  Attempting uninstall: ale-py\n","    Found existing installation: ale-py 0.10.1\n","    Uninstalling ale-py-0.10.1:\n","      Successfully uninstalled ale-py-0.10.1\n","Successfully installed ale-py-0.8.1\n","Requirement already satisfied: gymnasium[accept-rom-license] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (3.1.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (0.0.4)\n","Requirement already satisfied: autorom~=0.4.2 in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (0.4.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (8.1.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (4.66.6)\n","Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (0.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"accept-rom-license\"->gymnasium[accept-rom-license]) (2024.8.30)\n"]}]},{"cell_type":"code","source":["import gymnasium as gym; print(f'Gymnasium v{gym.__version__}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"grT4Yq9kcnT5","executionInfo":{"status":"ok","timestamp":1732916843222,"user_tz":300,"elapsed":135,"user":{"displayName":"Josh Mansky","userId":"05812403237052959145"}},"outputId":"70f21b93-3461-4479-bdd4-001780379cd9"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Gymnasium v0.29.1\n"]}]},{"cell_type":"code","source":["%%bash\n","\n","pip install \"stable-baselines3[extra]>=2.0.0a4\"\n","pip install sb3-contrib"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"I2Ngm0Muaj1n","executionInfo":{"status":"ok","timestamp":1732916854372,"user_tz":300,"elapsed":4904,"user":{"displayName":"Josh Mansky","userId":"05812403237052959145"}},"outputId":"5e1e3005-a7b3-464b-ed43-f6c8c5da482c"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: stable-baselines3>=2.0.0a4 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (2.5.0a0)\n","Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (0.29.1)\n","Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.26.4)\n","Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.5.1+cu121)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.1.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.8.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (4.10.0.84)\n","Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (2.6.1)\n","Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (2.17.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (5.9.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (4.66.6)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (13.9.4)\n","Collecting ale-py>=0.9.0 (from stable-baselines3[extra]>=2.0.0a4)\n","  Using cached ale_py-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]>=2.0.0a4) (11.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py>=0.9.0->stable-baselines3[extra]>=2.0.0a4) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (0.0.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.68.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (24.2)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (4.25.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (75.1.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.1.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2024.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]>=2.0.0a4) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]>=2.0.0a4) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a4) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.0.2)\n","Using cached ale_py-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","Installing collected packages: ale-py\n","  Attempting uninstall: ale-py\n","    Found existing installation: ale-py 0.8.1\n","    Uninstalling ale-py-0.8.1:\n","      Successfully uninstalled ale-py-0.8.1\n","Successfully installed ale-py-0.10.1\n","Requirement already satisfied: sb3-contrib in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: stable-baselines3<3.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from sb3-contrib) (2.5.0a0)\n","Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0->sb3-contrib) (0.29.1)\n","Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0->sb3-contrib) (1.26.4)\n","Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0->sb3-contrib) (2.5.1+cu121)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0->sb3-contrib) (3.1.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0->sb3-contrib) (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.4.0->sb3-contrib) (3.8.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (0.0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.3->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3<3.0,>=2.4.0->sb3-contrib) (3.0.2)\n"]}]},{"cell_type":"code","source":["from gymnasium import spaces\n","from stable_baselines3 import PPO\n","from stable_baselines3.common.env_util import make_atari_env\n","from stable_baselines3.common.vec_env import VecFrameStack\n","import numpy as np\n","from sb3_contrib import RecurrentPPO\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.vec_env import VecEnv, SubprocVecEnv\n","from stable_baselines3.common.vec_env import VecEnv, SubprocVecEnv\n","from stable_baselines3.common.torch_layers import BaseFeaturesExtractor, NatureCNN, create_mlp\n","import torch as th\n","from torch import nn\n","from sb3_contrib.common.recurrent.policies import RecurrentActorCriticPolicy\n","import crafter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"_gTmBLypD6fQ","executionInfo":{"status":"ok","timestamp":1732916943810,"user_tz":300,"elapsed":2424,"user":{"displayName":"Josh Mansky","userId":"05812403237052959145"}},"outputId":"a4013790-e69c-47cf-a162-d095e8c878d6"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"code","source":["class NotebookVecEnvWrapper(VecEnv):\n","    def __init__(self, venv, num_envs, notebook_size=8):\n","        self.venv = venv\n","        self.num_envs = num_envs\n","        # if type(venv.observation_space) != spaces.Discrete:\n","        #     raise ValueError(\"Only Discrete observation spaces are supported for now\")\n","        # if type(venv.action_space) != spaces.Discrete:\n","        #     raise ValueError(\"Only Discrete action spaces are supported for now\")\n","\n","        self.notebook_size = notebook_size\n","        self.notebook = np.ones(self.notebook_size, dtype=np.int32)\n","\n","        self.observation_space = spaces.Dict({\n","                                  \"env\": venv.observation_space,  # Original Observation Space\n","                                  \"notebook\": spaces.MultiDiscrete([2] * self.notebook_size)\n","                                 })\n","        self.action_space = spaces.MultiDiscrete([venv.action_space.n, self.notebook_size, 2])\n","        print(f\"Observation Space: {self.observation_space}\")\n","        print(f\"Action Space: {self.action_space}\")\n","\n","    def reset(self):\n","        observations = self.venv.reset()\n","        #observations = observations[np.newaxis, ...]\n","        #observations = observations.transpose(0, 3, 1, 2)\n","        single_env_shape = (84, 84, 4)\n","        observation_space = spaces.Box(low=0, high=255, shape=single_env_shape, dtype=np.uint8)\n","        observations = np.random.randint(0, 256, size=(self.num_envs, *single_env_shape), dtype=np.uint8)\n","        batch_observation_space = spaces.Box(low=0, high=255, shape=(self.num_envs, *single_env_shape), dtype=np.uint8)\n","        self.notebook = np.ones(self.notebook_size, dtype=np.int32)\n","        # print(f\"Reset Result is {observations.shape}\")\n","        # print(f\"VENV_OBS is {type(venv_obs)}\")\n","        reset_observation = {\n","                            \"env\": observations,  # Original Observation Space\n","                            \"notebook\": self.notebook\n","                            }\n","        return reset_observation\n","\n","    def step(self, action):\n","        venv_action, notebook_index, notebook_value = action\n","        venv_obs, reward, done, info = self.venv.step([venv_action])\n","        self.notebook[notebook_index] = notebook_value\n","        combined_observation = {\n","        \"env\": venv_obs,  # Observations from the original environment\n","        \"notebook\": self.notebook,  # Current notebook state\n","        }\n","        return combined_observation, reward, done, info\n","\n","    def env_is_wrapped(self, wrapper_class, indices=None):\n","        return self.venv.env_is_wrapped(wrapper_class, indices)\n","\n","    def get_attr(self, attr_name, indices=None):\n","        return self.venv.get_attr(attr_name, indices)\n","\n","    def set_attr(self, attr_name, value, indices=None):\n","        return self.venv.set_attr(attr_name, value, indices)\n","\n","    def env_method(self, method_name, *method_args, indices=None, **method_kwargs):\n","        return self.venv.env_method(method_name, *method_args, indices=indices, **method_kwargs)\n","\n","    def step_async(self, actions):\n","        self.venv.step_async(actions)\n","\n","    def step_wait(self):\n","        return self.venv.step_wait()\n","\n","    def render(self):\n","        return self.venv.render()\n","\n","    def close(self):\n","        return self.venv.close()\n","\n","    def seed(self, seed):\n","        return self.venv.seed(seed)\n","\n","    def __getattr__(self, attr):\n","        return getattr(self.venv, attr)\n","\n","    def __str__(self):\n","        return str(self.venv)\n","\n","    def __repr__(self):\n","        return repr(self.venv)"],"metadata":{"id":"2ranXnopO7JM","executionInfo":{"status":"ok","timestamp":1732916903892,"user_tz":300,"elapsed":150,"user":{"displayName":"Josh Mansky","userId":"05812403237052959145"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# There already exists an environment generator that will make and wrap atari environments correctly.\n","num_envs = 2\n","venv = make_atari_env(\"PongNoFrameskip-v4\", n_envs=num_envs, seed=0)\n","# Stack 4 frames\n","venv = VecFrameStack(venv, n_stack=4)\n","notebook_venv = NotebookVecEnvWrapper(venv, num_envs)\n","# notebook_venv.reset()\n","\n","# print(type(notebook_venv))\n","# print(notebook_venv.observation_space)\n","# print(notebook_venv.action_space)\n","\n","# # Test reset\n","# reset_obs = notebook_venv.reset()\n","# print(f\"Reset Observation Keys: {reset_obs.keys()}\")\n","# print(f\"Env Observation Shape: {reset_obs['env'].shape}\")\n","# print(f\"Notebook Observation Shape: {reset_obs['notebook'].shape}\")\n","\n","# # Test step\n","# # dummy_actions = np.array([notebook_venv.action_space.sample() for _ in range(num_envs)])\n","# dummy_action = [0, 0, 1]\n","# step_obs, reward, done, info = notebook_venv.step(dummy_action)\n","# print(f\"Step Observation Keys: {step_obs.keys()}\")\n","# print(f\"Env Observation Shape: {step_obs['env'].shape}\")\n","# print(f\"Notebook Observation Shape: {step_obs['notebook'].shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XVjMdhSbEeak","executionInfo":{"status":"ok","timestamp":1732910239061,"user_tz":300,"elapsed":532,"user":{"displayName":"Josh Mansky","userId":"05812403237052959145"}},"outputId":"373d300e-dc92-4739-bb8f-c5313db5d0cc"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Observation Space: Dict('env': Box(0, 255, (84, 84, 4), uint8), 'notebook': MultiDiscrete([2 2 2 2 2 2 2 2]))\n","Action Space: MultiDiscrete([6 8 2])\n"]}]},{"cell_type":"code","source":["class CombinedExtractor(BaseFeaturesExtractor):\n","    def __init__(self, observation_space: spaces.Dict):\n","        super(CombinedExtractor, self).__init__(observation_space, features_dim=128) # Adjust features_dim if needed\n","\n","        # Assuming 'env' key contains the image observations\n","        print(f\"Observation Space Env: {observation_space.spaces['env'].shape}\")\n","        print(f\"Observation Space Notebook: {observation_space.spaces['notebook'].shape}\")\n","        self.cnn = NatureCNN(observation_space.spaces['env'], features_dim=64) # Adjust features_dim if needed\n","        # Assuming 'notebook' key contains the notebook observations\n","        notebook_size = observation_space.spaces['notebook'].nvec[0]  # Get size of the notebook\n","        self.mlp = create_mlp(notebook_size, 64, [64])  # Adjust hidden layer size if needed\n","        self.mlp = nn.Sequential(*self.mlp)\n","\n","    def forward(self, observations) -> th.Tensor:\n","        # Debug raw input shapes\n","        print(f\"Raw env observation shape: {observations['env'].shape}\")\n","        print(f\"Raw notebook observation shape: {observations['notebook'].shape}\")\n","\n","        # Extract features from each part of the observation\n","        encoded_env = self.cnn(observations['env'])\n","        encoded_notebook = self.mlp(th.Tensor(observations['notebook']))\n","\n","        # Debug feature shapes\n","        print(f\"encoded_env shape: {encoded_env.shape}\")\n","        print(f\"encoded_notebook shape: {encoded_notebook.shape}\")\n","\n","        # Ensure batch sizes match\n","        if encoded_env.shape[0] != encoded_notebook.shape[0]:\n","            # Truncate or reshape notebook observations if needed\n","            encoded_notebook = encoded_notebook[:encoded_env.shape[0]]\n","            print(f\"Adjusted encoded_notebook shape: {encoded_notebook.shape}\")\n","\n","        # Concatenate the features\n","        return th.cat([encoded_env, encoded_notebook], dim=1)\n"],"metadata":{"id":"_M92lYAglaIL","executionInfo":{"status":"ok","timestamp":1732912345995,"user_tz":300,"elapsed":215,"user":{"displayName":"Josh Mansky","userId":"05812403237052959145"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["import torch as th\n","from stable_baselines3.common.preprocessing import is_image_space, preprocess_obs\n","from gymnasium import spaces\n","\n","def preprocess_obs(obs, observation_space, normalize_images=True):\n","    \"\"\"\n","    Preprocess observation to be to a neural network.\n","    For images, it normalizes the values by dividing by 255.\n","    For discrete observations, it create a one hot vector.\n","    :param obs: (np.ndarray)\n","    :param observation_space: (spaces.Space)\n","    :param normalize_images: (bool) Whether to normalize images or not,\n","        dividing by 255.0 if `True` (default)\n","    :return: (np.ndarray, th.Tensor)\n","    \"\"\"\n","    if isinstance(observation_space, spaces.Dict):\n","      preprocessed_obs = {}\n","      for key, _obs in obs.items():\n","          # Check if the key is 'notebook' to apply special handling\n","          if key == 'notebook':\n","              # Convert to one-hot encoding for MultiDiscrete 'notebook' observation\n","              _obs = _obs.type(th.int64)  # Ensure _obs is a PyTorch tensor with int64 dtype\n","              num_classes = observation_space[key].nvec[0]  # Assuming all nvec elements are equal\n","              preprocessed_obs[key] = th.nn.functional.one_hot(_obs, num_classes=num_classes).float()\n","\n","          else:\n","              # Preprocess other observations (e.g., images) normally\n","              preprocessed_obs[key] = preprocess_obs(_obs, observation_space[key], normalize_images=normalize_images)\n","\n","      return preprocessed_obs\n","    elif is_image_space(observation_space):\n","        # Normalize image\n","        return th.as_tensor(obs / 255.0, dtype=th.float32)\n","    elif isinstance(observation_space, spaces.Box):\n","        # For Box spaces, convert to tensor and potentially normalize\n","        return th.as_tensor(obs, dtype=th.float32)  # No normalization for now\n","    elif isinstance(observation_space, spaces.Discrete):\n","        # One hot encoding for Discrete space\n","        return th.nn.functional.one_hot(th.as_tensor(obs).long(), num_classes=observation_space.n).float()\n","    elif isinstance(observation_space, spaces.MultiDiscrete):\n","        # Special handling for MultiDiscrete spaces\n","        # Convert to tensor and perform one-hot encoding for each dimension\n","        return th.cat(\n","            [\n","                th.nn.functional.one_hot(th.as_tensor(obs_.astype(np.int64)), num_classes=int(observation_space.nvec[idx])).float()\n","                for idx, obs_ in enumerate(obs)\n","            ],\n","            dim=-1,\n","        )\n","    elif isinstance(observation_space, spaces.MultiBinary):\n","        return th.as_tensor(obs, dtype=th.float32)\n","    else:\n","        raise NotImplementedError(f\"Preprocessing not implemented for {observation_space}\")\n","\n","\n","class CustomRecurrentActorCriticPolicy(RecurrentActorCriticPolicy):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        env_obs_shape = self.observation_space.spaces[\"env\"].shape # Get the shape tuple\n","        print(f\"Env Observation Shape: {env_obs_shape}\")\n","        env_obs_size = env_obs_shape[0] # Calculate size from the shape\n","        notebook_obs_size = self.observation_space.spaces[\"notebook\"].nvec[0]\n","        total_input_size = 128\n","        self.lstm_actor.input_size = total_input_size\n","        if self.lstm_critic is not None:\n","            self.lstm_critic.input_size = total_input_size\n","\n","    def extract_features(self, obs: th.Tensor) -> th.Tensor:\n","        \"\"\"\n","        Preprocess the observation if needed and extract features.\n","\n","        :param obs:\n","        :return:\n","        \"\"\"\n","        # Call your custom preprocess_obs function here\n","        preprocessed_obs = preprocess_obs(obs, self.observation_space, normalize_images=self.normalize_images)\n","        preprocessed_obs['notebook'] = th.as_tensor(preprocessed_obs['notebook'])\n","        print(f\"preprocessed_obs[env] = {preprocessed_obs['env'].shape}\")\n","        #batch_size = preprocessed_obs['env'].shape[0]\n","        # Flatten the rest of the dimensions (except batch)\n","        #preprocessed_obs['env'] = preprocessed_obs['env'].reshape(batch_size, -1)\n","        return self.features_extractor(preprocessed_obs)\n","\n","    @staticmethod\n","    def _process_sequence(features, lstm_states, episode_starts, lstm):\n","        \"\"\"\n","        Process input sequence with the LSTM.\n","\n","        :param features: Features tensor of shape (batch_size, input_size).\n","        :param lstm_states: Tuple of initial hidden and cell states (h_0, c_0).\n","        :param episode_starts: A tensor indicating the start of new episodes.\n","        :param lstm: The LSTM module to process the sequence.\n","        :return: Processed sequence and updated LSTM states.\n","        \"\"\"\n","        batch_size, input_size = features.shape\n","        n_seq = 2  # Number of sequences (adjust as needed)\n","        max_length = batch_size // n_seq\n","\n","        # Reshape and transpose to match LSTM input shape (seq_len, batch, input_size)\n","        features_sequence = features.view((n_seq, max_length, input_size)).swapaxes(0, 1)\n","        print(f\"Features Sequence Shape: {features_sequence.shape}\")\n","\n","        # Process the sequence with the LSTM\n","        lstm_output, lstm_states = lstm(features_sequence, lstm_states)\n","\n","        return lstm_output, lstm_states"],"metadata":{"id":"clkUtNbGaT4u","executionInfo":{"status":"ok","timestamp":1732912341513,"user_tz":300,"elapsed":223,"user":{"displayName":"Josh Mansky","userId":"05812403237052959145"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["model = RecurrentPPO(\n","    CustomRecurrentActorCriticPolicy,\n","    notebook_venv,\n","    verbose=1,\n","    policy_kwargs={\n","        \"features_extractor_class\": CombinedExtractor,\n","        \"features_extractor_kwargs\": {}, # Optional: You can pass extra kwargs to the extractor\n","        \"net_arch\": [dict(pi=[64, 64], vf=[64, 64], lstm=[128, 128])], # Adjust net_arch if needed\n","        \"lstm_hidden_size\": 128,\n","    },\n",")\n","model.learn(2000000)\n","\n","vec_env = model.get_env()\n","mean_reward, std_reward = evaluate_policy(model, vec_env, n_eval_episodes=20, warn=False)\n","print(mean_reward)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":615},"id":"_smIV4qbEfv_","executionInfo":{"status":"error","timestamp":1732912350072,"user_tz":300,"elapsed":347,"user":{"displayName":"Josh Mansky","userId":"05812403237052959145"}},"outputId":"d9664846-b413-4dbf-cc5c-2e971c2ee318"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n","Wrapping the env in a VecTransposeImage.\n","Observation Space Env: (4, 84, 84)\n","Observation Space Notebook: (8,)\n","Env Observation Shape: (4, 84, 84)\n","preprocessed_obs[env] = torch.Size([2, 4, 84, 84])\n","Raw env observation shape: torch.Size([2, 4, 84, 84])\n","Raw notebook observation shape: torch.Size([8, 2])\n","encoded_env shape: torch.Size([2, 64])\n","encoded_notebook shape: torch.Size([8, 64])\n","Adjusted encoded_notebook shape: torch.Size([2, 64])\n","Features Sequence Shape: torch.Size([1, 2, 128])\n","Features Sequence Shape: torch.Size([1, 2, 128])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"split_with_sizes expects split_sizes to sum exactly to 2 (input tensor's size at dimension 1), but got split_sizes=[6, 8, 2]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-6a27057d1575>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     },\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mvec_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sb3_contrib/ppo_recurrent/ppo_recurrent.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     ) -> SelfRecurrentPPO:\n\u001b[0;32m--> 450\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    451\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sb3_contrib/ppo_recurrent/ppo_recurrent.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0mobs_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs_as_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0mepisode_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_episode_starts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                 \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_starts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sb3_contrib/common/recurrent/policies.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs, lstm_states, episode_starts, deterministic)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# Evaluate the values for the given observations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_action_dist_from_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36m_get_action_dist_from_latent\u001b[0;34m(self, latent_pi)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiCategoricalDistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             \u001b[0;31m# Here mean_actions are the flattened logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBernoulliDistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Here mean_actions are the logits (before rounding to get the binary actions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, action_logits)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSelfMultiCategoricalDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_logits\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     ) -> SelfMultiCategoricalDistribution:\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(tensor, split_size_or_sections, dim)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;31m# split_size_or_sections. The branching code is in _tensor.py, which we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;31m# call here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size_or_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, split_size, dim)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_with_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: split_with_sizes expects split_sizes to sum exactly to 2 (input tensor's size at dimension 1), but got split_sizes=[6, 8, 2]"]}]}]}